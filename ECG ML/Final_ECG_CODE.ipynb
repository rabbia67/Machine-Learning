{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC-cIts_e7ph",
        "outputId": "e05f02f0-97ad-4923-be56-83bedada4cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIME not available. Install with: pip install lime\n",
            "================================================================================\n",
            "ENHANCED ECG CLASSIFICATION WITH STATISTICAL ANALYSIS AND INTERPRETABILITY\n",
            "================================================================================\n",
            "\n",
            "1. LOADING DATASETS...\n",
            "--------------------------------------------------------------------------------\n",
            "✓ MIT-BIH train: (21892, 188)\n",
            "✓ MIT-BIH test: (21892, 188)\n",
            "✓ PTB-DB normal: (4046, 188)\n",
            "✓ PTB-DB abnormal: (10506, 188)\n",
            "\n",
            "2. DATASET CHARACTERISTICS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "MIT-BIH:\n",
            "  Source: MIT-BIH Arrhythmia Database\n",
            "  Sampling Rate: 125 Hz (resampled from 360 Hz)\n",
            "  Signal Length: 187 samples per heartbeat\n",
            "  Number of Leads: 1 lead (modified lead II)\n",
            "  Total Samples Train: 21892\n",
            "  Total Samples Test: 21892\n",
            "\n",
            "PTB-DB:\n",
            "  Source: PTB Diagnostic ECG Database\n",
            "  Sampling Rate: 125 Hz\n",
            "  Signal Length: 187 samples per heartbeat\n",
            "  Number of Leads: 1 lead (preprocessed)\n",
            "  Normal Samples: 4046\n",
            "  Abnormal Samples: 10506\n",
            "\n",
            "3. PREPARING BINARY CLASSIFICATION\n",
            "--------------------------------------------------------------------------------\n",
            "MIT-BIH train - Normal: 18118, Abnormal: 3774\n",
            "PTB-DB - Normal: 4046, Abnormal: 10506\n",
            "\n",
            "4. FEATURE EXTRACTION\n",
            "--------------------------------------------------------------------------------\n",
            "Extracting features from MIT-BIH...\n",
            "Extracting features from PTB-DB...\n",
            "Total features extracted: 19\n",
            "Total samples: 58336\n",
            "Class distribution - Normal: 40282, Abnormal: 18054\n",
            "\n",
            "5. TRAIN-TEST SPLIT\n",
            "--------------------------------------------------------------------------------\n",
            "NOTE: Using stratified random split. Patient-level splitting requires patient IDs.\n",
            "Recommendation: If patient IDs available, use GroupShuffleSplit to prevent data leakage.\n",
            "Training set: 46668 samples\n",
            "Test set: 11668 samples\n",
            "Train - Normal: 32225, Abnormal: 14443\n",
            "Test - Normal: 8057, Abnormal: 3611\n",
            "\n",
            "6. FEATURE SCALING\n",
            "--------------------------------------------------------------------------------\n",
            "Scaled feature range: [-72.11, 91.43]\n",
            "\n",
            "7. MODEL TRAINING WITH COMPUTATIONAL COST ANALYSIS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Training Random Forest...\n",
            "  Training Time: 16.85s\n",
            "  Memory Used: 27.00 MB\n",
            "  Accuracy: 0.9939\n",
            "  AUC: 0.9991\n",
            "  Sensitivity: 0.9834\n",
            "  Specificity: 0.9986\n",
            "  False Negatives: 60 (Clinical Risk)\n",
            "\n",
            "Training Gradient Boosting...\n",
            "  Training Time: 34.62s\n",
            "  Memory Used: 2.44 MB\n",
            "  Accuracy: 0.9552\n",
            "  AUC: 0.9790\n",
            "  Sensitivity: 0.8779\n",
            "  Specificity: 0.9898\n",
            "  False Negatives: 441 (Clinical Risk)\n",
            "\n",
            "Training SVM...\n",
            "  Training Time: 111.00s\n",
            "  Memory Used: 226.36 MB\n",
            "  Accuracy: 0.9595\n",
            "  AUC: 0.9799\n",
            "  Sensitivity: 0.8851\n",
            "  Specificity: 0.9928\n",
            "  False Negatives: 415 (Clinical Risk)\n",
            "\n",
            "Training Neural Network...\n",
            "  Training Time: 44.74s\n",
            "  Memory Used: 0.21 MB\n",
            "  Accuracy: 0.9819\n",
            "  AUC: 0.9961\n",
            "  Sensitivity: 0.9745\n",
            "  Specificity: 0.9852\n",
            "  False Negatives: 92 (Clinical Risk)\n",
            "\n",
            "✓ Computational cost analysis saved to enhanced_results/computational_cost_analysis.csv\n",
            "\n",
            "8. CROSS-VALIDATION ANALYSIS \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Cross-validating Random Forest...\n",
            "  Mean AUC: 0.9983 ± 0.0004\n",
            "  95% CI: [0.9979, 0.9986]\n",
            "\n",
            "Cross-validating Gradient Boosting...\n",
            "  Mean AUC: 0.9783 ± 0.0014\n",
            "  95% CI: [0.9770, 0.9795]\n",
            "\n",
            "Cross-validating SVM...\n",
            "  Mean AUC: 0.9770 ± 0.0001\n",
            "  95% CI: [0.9769, 0.9771]\n",
            "\n",
            "Cross-validating Neural Network...\n",
            "  Mean AUC: 0.9943 ± 0.0014\n",
            "  95% CI: [0.9931, 0.9954]\n",
            "\n",
            "9. STATISTICAL SIGNIFICANCE TESTING\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Random Forest vs Gradient Boosting:\n",
            "  McNemar χ² = 438.3642, p = 0.0000\n",
            "  Significant: Yes (α=0.05)\n",
            "\n",
            "Random Forest vs SVM:\n",
            "  McNemar χ² = 362.1644, p = 0.0000\n",
            "  Significant: Yes (α=0.05)\n",
            "\n",
            "Random Forest vs Neural Network:\n",
            "  McNemar χ² = 87.0315, p = 0.0000\n",
            "  Significant: Yes (α=0.05)\n",
            "\n",
            "✓ Statistical tests saved to enhanced_results/statistical_significance_tests.csv\n",
            "\n",
            "10. MODEL INTERPRETABILITY - SHAP ANALYSIS\n",
            "--------------------------------------------------------------------------------\n",
            "Generating SHAP values for Random Forest...\n",
            "✓ SHAP plots saved to enhanced_results/\n",
            "\n",
            "Top 10 Most Important Features (SHAP):\n",
            "Error generating SHAP plots: unsupported format string passed to numpy.ndarray.__format__\n",
            "\n",
            "11. HYPERPARAMETER OPTIMIZATION\n",
            "--------------------------------------------------------------------------------\n",
            "Performing GridSearchCV for Random Forest...\n",
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Enhanced ECG Machine Learning Classification with Statistical Analysis and Interpretability\n",
        "Addresses: Statistical Significance, Computational Cost, Interpretability\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, roc_curve,\n",
        "                            roc_auc_score, precision_recall_curve, average_precision_score,\n",
        "                            matthews_corrcoef, cohen_kappa_score)\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# For statistical testing\n",
        "from scipy import stats\n",
        "from scipy.stats import ttest_rel, wilcoxon\n",
        "import statsmodels.stats.api as sms\n",
        "\n",
        "# For interpretability\n",
        "import shap\n",
        "try:\n",
        "    import lime\n",
        "    import lime.lime_tabular\n",
        "    LIME_AVAILABLE = True\n",
        "except ImportError:\n",
        "    LIME_AVAILABLE = False\n",
        "    print(\"LIME not available. Install with: pip install lime\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "plt.style.use('ggplot')\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# ==========================================\n",
        "# UTILITY FUNCTIONS FOR COMPUTATIONAL COST\n",
        "# ==========================================\n",
        "\n",
        "def get_memory_usage():\n",
        "    \"\"\"Get current memory usage in MB\"\"\"\n",
        "    process = psutil.Process(os.getpid())\n",
        "    return process.memory_info().rss / 1024 / 1024  # Convert to MB\n",
        "\n",
        "def track_computational_cost(func):\n",
        "    \"\"\"Decorator to track time and memory usage\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        start_memory = get_memory_usage()\n",
        "\n",
        "        result = func(*args, **kwargs)\n",
        "\n",
        "        end_time = time.time()\n",
        "        end_memory = get_memory_usage()\n",
        "\n",
        "        cost_info = {\n",
        "            'time_seconds': end_time - start_time,\n",
        "            'memory_mb': end_memory - start_memory,\n",
        "            'peak_memory_mb': end_memory\n",
        "        }\n",
        "\n",
        "        return result, cost_info\n",
        "    return wrapper\n",
        "\n",
        "# ==========================================\n",
        "# DATA LOADING AND PREPROCESSING\n",
        "# ==========================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ENHANCED ECG CLASSIFICATION WITH STATISTICAL ANALYSIS AND INTERPRETABILITY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Dataset paths - UPDATE THESE TO YOUR ACTUAL PATHS\n",
        "MITBIH_TRAIN_PATH = \"/content/drive/MyDrive/ECG_Datasets/ECG_ML/mitbih_test.csv\"\n",
        "MITBIH_TEST_PATH = \"/content/drive/MyDrive/ECG_Datasets/ECG_ML/mitbih_test.csv\"\n",
        "PTBDB_NORMAL_PATH = \"/content/drive/MyDrive/ECG_Datasets/ECG_ML/ptbdb_normal.csv\"\n",
        "PTBDB_ABNORMAL_PATH = \"/content/drive/MyDrive/ECG_Datasets/ECG_ML/ptbdb_abnormal.csv\"\n",
        "\n",
        "# Results directory\n",
        "RESULTS_DIR = \"enhanced_results\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(\"\\n1. LOADING DATASETS...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Load datasets with error handling\n",
        "try:\n",
        "    mitbih_train = pd.read_csv(MITBIH_TRAIN_PATH, header=None)\n",
        "    mitbih_test = pd.read_csv(MITBIH_TEST_PATH, header=None)\n",
        "    ptbdb_normal = pd.read_csv(PTBDB_NORMAL_PATH, header=None)\n",
        "    ptbdb_abnormal = pd.read_csv(PTBDB_ABNORMAL_PATH, header=None)\n",
        "\n",
        "    print(f\"✓ MIT-BIH train: {mitbih_train.shape}\")\n",
        "    print(f\"✓ MIT-BIH test: {mitbih_test.shape}\")\n",
        "    print(f\"✓ PTB-DB normal: {ptbdb_normal.shape}\")\n",
        "    print(f\"✓ PTB-DB abnormal: {ptbdb_abnormal.shape}\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"ERROR: {e}\")\n",
        "    print(\"Please update the file paths in the script.\")\n",
        "    exit(1)\n",
        "\n",
        "# Document dataset characteristics\n",
        "print(\"\\n2. DATASET CHARACTERISTICS\")\n",
        "print(\"-\" * 80)\n",
        "dataset_info = {\n",
        "    'MIT-BIH': {\n",
        "        'Source': 'MIT-BIH Arrhythmia Database',\n",
        "        'Sampling Rate': '125 Hz (resampled from 360 Hz)',\n",
        "        'Signal Length': '187 samples per heartbeat',\n",
        "        'Number of Leads': '1 lead (modified lead II)',\n",
        "        'Total Samples Train': len(mitbih_train),\n",
        "        'Total Samples Test': len(mitbih_test)\n",
        "    },\n",
        "    'PTB-DB': {\n",
        "        'Source': 'PTB Diagnostic ECG Database',\n",
        "        'Sampling Rate': '125 Hz',\n",
        "        'Signal Length': '187 samples per heartbeat',\n",
        "        'Number of Leads': '1 lead (preprocessed)',\n",
        "        'Normal Samples': len(ptbdb_normal),\n",
        "        'Abnormal Samples': len(ptbdb_abnormal)\n",
        "    }\n",
        "}\n",
        "\n",
        "for dataset, info in dataset_info.items():\n",
        "    print(f\"\\n{dataset}:\")\n",
        "    for key, value in info.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "# Save dataset documentation\n",
        "with open(f\"{RESULTS_DIR}/dataset_characteristics.txt\", 'w') as f:\n",
        "    f.write(\"DATASET CHARACTERISTICS FOR REVIEW\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    for dataset, info in dataset_info.items():\n",
        "        f.write(f\"{dataset}:\\n\")\n",
        "        for key, value in info.items():\n",
        "            f.write(f\"  {key}: {value}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "# ==========================================\n",
        "# BINARY CLASSIFICATION PREPARATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n3. PREPARING BINARY CLASSIFICATION\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def mitbih_to_binary(label):\n",
        "    \"\"\"Convert MIT-BIH multi-class to binary: 0=Normal, 1=Abnormal\"\"\"\n",
        "    return 0 if label == 0 else 1\n",
        "\n",
        "# MIT-BIH processing\n",
        "X_mitbih_train = mitbih_train.iloc[:, :-1]\n",
        "y_mitbih_train_binary = mitbih_train.iloc[:, -1].apply(mitbih_to_binary)\n",
        "\n",
        "X_mitbih_test = mitbih_test.iloc[:, :-1]\n",
        "y_mitbih_test_binary = mitbih_test.iloc[:, -1].apply(mitbih_to_binary)\n",
        "\n",
        "# PTB-DB processing\n",
        "ptbdb_normal['label'] = 0\n",
        "ptbdb_abnormal['label'] = 1\n",
        "ptbdb_combined = pd.concat([ptbdb_normal, ptbdb_abnormal], axis=0)\n",
        "X_ptbdb = ptbdb_combined.iloc[:, :-1]\n",
        "y_ptbdb = ptbdb_combined.iloc[:, -1]\n",
        "\n",
        "print(f\"MIT-BIH train - Normal: {(y_mitbih_train_binary==0).sum()}, Abnormal: {(y_mitbih_train_binary==1).sum()}\")\n",
        "print(f\"PTB-DB - Normal: {(y_ptbdb==0).sum()}, Abnormal: {(y_ptbdb==1).sum()}\")\n",
        "\n",
        "# ==========================================\n",
        "# FEATURE ENGINEERING\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n4. FEATURE EXTRACTION\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def extract_time_features(signals_df):\n",
        "    \"\"\"Extract comprehensive time-domain ECG features\"\"\"\n",
        "    features = pd.DataFrame()\n",
        "\n",
        "    # Basic statistics\n",
        "    features['mean'] = signals_df.mean(axis=1)\n",
        "    features['std'] = signals_df.std(axis=1)\n",
        "    features['min'] = signals_df.min(axis=1)\n",
        "    features['max'] = signals_df.max(axis=1)\n",
        "    features['range'] = features['max'] - features['min']\n",
        "    features['median'] = signals_df.median(axis=1)\n",
        "\n",
        "    # RMS (Root Mean Square)\n",
        "    features['rms'] = np.sqrt((signals_df**2).mean(axis=1))\n",
        "\n",
        "    # Skewness and Kurtosis\n",
        "    features['skewness'] = signals_df.skew(axis=1)\n",
        "    features['kurtosis'] = signals_df.kurtosis(axis=1)\n",
        "\n",
        "    # Quartiles\n",
        "    features['q25'] = signals_df.quantile(0.25, axis=1)\n",
        "    features['q75'] = signals_df.quantile(0.75, axis=1)\n",
        "    features['iqr'] = features['q75'] - features['q25']\n",
        "\n",
        "    # First derivative statistics\n",
        "    diff1 = signals_df.diff(axis=1).iloc[:, 1:]\n",
        "    features['mean_d1'] = diff1.mean(axis=1)\n",
        "    features['std_d1'] = diff1.std(axis=1)\n",
        "    features['max_d1'] = diff1.max(axis=1)\n",
        "    features['min_d1'] = diff1.min(axis=1)\n",
        "\n",
        "    # Second derivative statistics\n",
        "    diff2 = signals_df.diff(axis=1).diff(axis=1).iloc[:, 2:]\n",
        "    features['mean_d2'] = diff2.mean(axis=1)\n",
        "    features['std_d2'] = diff2.std(axis=1)\n",
        "    features['max_d2'] = diff2.max(axis=1)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Extract features\n",
        "print(\"Extracting features from MIT-BIH...\")\n",
        "X_mitbih_all = pd.concat([X_mitbih_train, X_mitbih_test], axis=0)\n",
        "y_mitbih_all = pd.concat([y_mitbih_train_binary, y_mitbih_test_binary], axis=0)\n",
        "X_mitbih_features = extract_time_features(X_mitbih_all)\n",
        "\n",
        "print(\"Extracting features from PTB-DB...\")\n",
        "X_ptbdb_features = extract_time_features(X_ptbdb)\n",
        "\n",
        "# Combine datasets\n",
        "X_combined_features = pd.concat([X_mitbih_features, X_ptbdb_features], axis=0)\n",
        "y_combined = pd.concat([y_mitbih_all, y_ptbdb], axis=0)\n",
        "\n",
        "print(f\"Total features extracted: {X_combined_features.shape[1]}\")\n",
        "print(f\"Total samples: {X_combined_features.shape[0]}\")\n",
        "print(f\"Class distribution - Normal: {(y_combined==0).sum()}, Abnormal: {(y_combined==1).sum()}\")\n",
        "\n",
        "# ==========================================\n",
        "# TRAIN-TEST SPLIT\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n5. TRAIN-TEST SPLIT\")\n",
        "print(\"-\" * 80)\n",
        "print(\"NOTE: Using stratified random split. Patient-level splitting requires patient IDs.\")\n",
        "print(\"Recommendation: If patient IDs available, use GroupShuffleSplit to prevent data leakage.\")\n",
        "\n",
        "X_train_features, X_test_features, y_train, y_test = train_test_split(\n",
        "    X_combined_features, y_combined,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_combined\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train_features.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test_features.shape[0]} samples\")\n",
        "print(f\"Train - Normal: {(y_train==0).sum()}, Abnormal: {(y_train==1).sum()}\")\n",
        "print(f\"Test - Normal: {(y_test==0).sum()}, Abnormal: {(y_test==1).sum()}\")\n",
        "\n",
        "# ==========================================\n",
        "# FEATURE SCALING\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n6. FEATURE SCALING\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_features)\n",
        "X_test_scaled = scaler.transform(X_test_features)\n",
        "\n",
        "print(f\"Scaled feature range: [{X_train_scaled.min():.2f}, {X_train_scaled.max():.2f}]\")\n",
        "\n",
        "# ==========================================\n",
        "# MODEL TRAINING WITH COMPUTATIONAL COST TRACKING\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n7. MODEL TRAINING WITH COMPUTATIONAL COST ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'Neural Network': MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "computational_costs = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "\n",
        "    # Track computational cost\n",
        "    start_time = time.time()\n",
        "    start_memory = get_memory_usage()\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    end_time = time.time()\n",
        "    end_memory = get_memory_usage()\n",
        "\n",
        "    # Record costs\n",
        "    training_time = end_time - start_time\n",
        "    memory_used = end_memory - start_memory\n",
        "\n",
        "    computational_costs[name] = {\n",
        "        'Training Time (s)': training_time,\n",
        "        'Memory Usage (MB)': memory_used,\n",
        "        'Peak Memory (MB)': end_memory\n",
        "    }\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = model.score(X_test_scaled, y_test)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    auc = roc_auc_score(y_test, y_proba)\n",
        "    mcc = matthews_corrcoef(y_test, y_pred)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Clinical metrics\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': report['1']['precision'],\n",
        "        'recall': report['1']['recall'],\n",
        "        'sensitivity': sensitivity,  # Same as recall for abnormal class\n",
        "        'specificity': specificity,\n",
        "        'f1': report['1']['f1-score'],\n",
        "        'auc': auc,\n",
        "        'mcc': mcc,\n",
        "        'kappa': kappa,\n",
        "        'y_pred': y_pred,\n",
        "        'y_proba': y_proba,\n",
        "        'confusion_matrix': cm,\n",
        "        'false_negatives': fn,\n",
        "        'false_positives': fp\n",
        "    }\n",
        "\n",
        "    print(f\"  Training Time: {training_time:.2f}s\")\n",
        "    print(f\"  Memory Used: {memory_used:.2f} MB\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"  AUC: {auc:.4f}\")\n",
        "    print(f\"  Sensitivity: {sensitivity:.4f}\")\n",
        "    print(f\"  Specificity: {specificity:.4f}\")\n",
        "    print(f\"  False Negatives: {fn} (Clinical Risk)\")\n",
        "\n",
        "# Save computational cost report\n",
        "cost_df = pd.DataFrame(computational_costs).T\n",
        "cost_df.to_csv(f\"{RESULTS_DIR}/computational_cost_analysis.csv\")\n",
        "print(f\"\\n✓ Computational cost analysis saved to {RESULTS_DIR}/computational_cost_analysis.csv\")\n",
        "\n",
        "# ==========================================\n",
        "# CROSS-VALIDATION\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n8. CROSS-VALIDATION ANALYSIS \")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "cv_results = {}\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nCross-validating {name}...\")\n",
        "\n",
        "    # Perform cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "    cv_results[name] = {\n",
        "        'mean_auc': cv_scores.mean(),\n",
        "        'std_auc': cv_scores.std(),\n",
        "        'scores': cv_scores,\n",
        "        '95%_ci_lower': cv_scores.mean() - 1.96 * (cv_scores.std() / np.sqrt(5)),\n",
        "        '95%_ci_upper': cv_scores.mean() + 1.96 * (cv_scores.std() / np.sqrt(5))\n",
        "    }\n",
        "\n",
        "    print(f\"  Mean AUC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "    print(f\"  95% CI: [{cv_results[name]['95%_ci_lower']:.4f}, {cv_results[name]['95%_ci_upper']:.4f}]\")\n",
        "\n",
        "# ==========================================\n",
        "# STATISTICAL SIGNIFICANCE TESTING\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n9. STATISTICAL SIGNIFICANCE TESTING\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Compare best model (Random Forest) with others\n",
        "best_model_name = 'Random Forest'\n",
        "statistical_tests = {}\n",
        "\n",
        "for name in models.keys():\n",
        "    if name != best_model_name:\n",
        "        # McNemar's test for paired predictions\n",
        "        rf_pred = results[best_model_name]['y_pred']\n",
        "        other_pred = results[name]['y_pred']\n",
        "\n",
        "        # Create contingency table\n",
        "        both_correct = np.sum((rf_pred == y_test) & (other_pred == y_test))\n",
        "        rf_correct_other_wrong = np.sum((rf_pred == y_test) & (other_pred != y_test))\n",
        "        rf_wrong_other_correct = np.sum((rf_pred != y_test) & (other_pred == y_test))\n",
        "        both_wrong = np.sum((rf_pred != y_test) & (other_pred != y_test))\n",
        "\n",
        "        # McNemar's test\n",
        "        contingency_table = [[both_correct, rf_correct_other_wrong],\n",
        "                           [rf_wrong_other_correct, both_wrong]]\n",
        "\n",
        "        # Calculate McNemar statistic\n",
        "        b = rf_correct_other_wrong\n",
        "        c = rf_wrong_other_correct\n",
        "        mcnemar_stat = ((abs(b - c) - 1)**2) / (b + c) if (b + c) > 0 else 0\n",
        "        p_value = 1 - stats.chi2.cdf(mcnemar_stat, 1)\n",
        "\n",
        "        statistical_tests[f\"{best_model_name} vs {name}\"] = {\n",
        "            'McNemar Statistic': mcnemar_stat,\n",
        "            'p-value': p_value,\n",
        "            'Significant (p<0.05)': p_value < 0.05,\n",
        "            'RF correct, Other wrong': rf_correct_other_wrong,\n",
        "            'RF wrong, Other correct': rf_wrong_other_correct\n",
        "        }\n",
        "\n",
        "        print(f\"\\n{best_model_name} vs {name}:\")\n",
        "        print(f\"  McNemar χ² = {mcnemar_stat:.4f}, p = {p_value:.4f}\")\n",
        "        print(f\"  Significant: {'Yes' if p_value < 0.05 else 'No'} (α=0.05)\")\n",
        "\n",
        "# Save statistical test results\n",
        "stat_df = pd.DataFrame(statistical_tests).T\n",
        "stat_df.to_csv(f\"{RESULTS_DIR}/statistical_significance_tests.csv\")\n",
        "print(f\"\\n✓ Statistical tests saved to {RESULTS_DIR}/statistical_significance_tests.csv\")\n",
        "\n",
        "# ==========================================\n",
        "# INTERPRETABILITY: SHAP VALUES\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n10. MODEL INTERPRETABILITY - SHAP ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "best_model = results[best_model_name]['model']\n",
        "\n",
        "print(f\"Generating SHAP values for {best_model_name}...\")\n",
        "try:\n",
        "    # Use TreeExplainer for tree-based models\n",
        "    explainer = shap.TreeExplainer(best_model)\n",
        "    shap_values = explainer.shap_values(X_test_scaled)\n",
        "\n",
        "    # For binary classification, get values for class 1 (Abnormal)\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values_class1 = shap_values[1]\n",
        "    else:\n",
        "        shap_values_class1 = shap_values\n",
        "\n",
        "    # Summary plot\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    shap.summary_plot(shap_values_class1, X_test_scaled,\n",
        "                     feature_names=X_combined_features.columns,\n",
        "                     show=False, max_display=15)\n",
        "    plt.title(f'SHAP Summary Plot - {best_model_name} (Abnormal Class)', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/shap_summary_plot.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Feature importance plot\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    shap.summary_plot(shap_values_class1, X_test_scaled,\n",
        "                     feature_names=X_combined_features.columns,\n",
        "                     plot_type=\"bar\", show=False, max_display=15)\n",
        "    plt.title(f'SHAP Feature Importance - {best_model_name}', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{RESULTS_DIR}/shap_feature_importance.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"✓ SHAP plots saved to {RESULTS_DIR}/\")\n",
        "\n",
        "    # Get top 10 most important features\n",
        "    feature_importance = np.abs(shap_values_class1).mean(axis=0)\n",
        "    feature_names = X_combined_features.columns\n",
        "    top_indices = np.argsort(feature_importance)[-10:][::-1]\n",
        "\n",
        "    print(\"\\nTop 10 Most Important Features (SHAP):\")\n",
        "    for idx in top_indices:\n",
        "        print(f\"  {feature_names[idx]}: {feature_importance[idx]:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error generating SHAP plots: {e}\")\n",
        "\n",
        "# ==========================================\n",
        "# HYPERPARAMETER TUNING\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n11. HYPERPARAMETER OPTIMIZATION\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Grid search for Random Forest\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "print(\"Performing GridSearchCV for Random Forest...\")\n",
        "rf_grid = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    rf_param_grid,\n",
        "    cv=5,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rf_grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters: {rf_grid.best_params_}\")\n",
        "print(f\"Best cross-validation AUC: {rf_grid.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate tuned model\n",
        "tuned_model = rf_grid.best_estimator_\n",
        "y_pred_tuned = tuned_model.predict(X_test_scaled)\n",
        "y_proba_tuned = tuned_model.predict_proba(X_test_scaled)[:, 1]\n",
        "auc_tuned = roc_auc_score(y_test, y_proba_tuned)\n",
        "\n",
        "print(f\"Tuned model test AUC: {auc_tuned:.4f}\")\n",
        "print(f\"Improvement: {auc_tuned - results[best_model_name]['auc']:.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# VISUALIZATION AND REPORTING\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n12. GENERATING COMPREHENSIVE REPORTS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Model comparison table\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Model': list(results.keys()),\n",
        "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
        "    'Precision': [results[m]['precision'] for m in results],\n",
        "    'Recall/Sensitivity': [results[m]['recall'] for m in results],\n",
        "    'Specificity': [results[m]['specificity'] for m in results],\n",
        "    'F1 Score': [results[m]['f1'] for m in results],\n",
        "    'AUC': [results[m]['auc'] for m in results],\n",
        "    'MCC': [results[m]['mcc'] for m in results],\n",
        "    'Kappa': [results[m]['kappa'] for m in results],\n",
        "    'False Negatives': [results[m]['false_negatives'] for m in results],\n",
        "    'Training Time (s)': [computational_costs[m]['Training Time (s)'] for m in results]\n",
        "})\n",
        "\n",
        "metrics_df.to_csv(f\"{RESULTS_DIR}/comprehensive_model_comparison.csv\", index=False)\n",
        "print(f\"✓ Model comparison saved to {RESULTS_DIR}/comprehensive_model_comparison.csv\")\n",
        "\n",
        "# Create comprehensive visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# 1. ROC Curves with CI\n",
        "ax = axes[0, 0]\n",
        "for name, result in results.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, result['y_proba'])\n",
        "    ci_lower = cv_results[name]['95%_ci_lower']\n",
        "    ci_upper = cv_results[name]['95%_ci_upper']\n",
        "    ax.plot(fpr, tpr, label=f\"{name} (AUC={result['auc']:.4f}, 95% CI: [{ci_lower:.3f}, {ci_upper:.3f}])\")\n",
        "ax.plot([0, 1], [0, 1], 'k--')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.set_title('ROC Curves with 95% Confidence Intervals')\n",
        "ax.legend(loc='lower right', fontsize=8)\n",
        "ax.grid(True)\n",
        "\n",
        "# 2. Computational Cost Comparison\n",
        "ax = axes[0, 1]\n",
        "models_list = list(computational_costs.keys())\n",
        "training_times = [computational_costs[m]['Training Time (s)'] for m in models_list]\n",
        "ax.bar(models_list, training_times, color='steelblue')\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('Training Time (seconds)')\n",
        "ax.set_title('Computational Cost - Training Time')\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 3. Memory Usage\n",
        "ax = axes[0, 2]\n",
        "memory_usage = [computational_costs[m]['Memory Usage (MB)'] for m in models_list]\n",
        "ax.bar(models_list, memory_usage, color='coral')\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('Memory Usage (MB)')\n",
        "ax.set_title('Computational Cost - Memory Usage')\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 4. Clinical Metrics (Sensitivity vs Specificity)\n",
        "ax = axes[1, 0]\n",
        "sensitivities = [results[m]['sensitivity'] for m in results]\n",
        "specificities = [results[m]['specificity'] for m in results]\n",
        "x = np.arange(len(results))\n",
        "width = 0.35\n",
        "ax.bar(x - width/2, sensitivities, width, label='Sensitivity', color='green', alpha=0.7)\n",
        "ax.bar(x + width/2, specificities, width, label='Specificity', color='blue', alpha=0.7)\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Clinical Metrics: Sensitivity vs Specificity')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(list(results.keys()), rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. False Negatives Analysis\n",
        "ax = axes[1, 1]\n",
        "false_negatives = [results[m]['false_negatives'] for m in results]\n",
        "colors = ['red' if fn == max(false_negatives) else 'orange' for fn in false_negatives]\n",
        "ax.bar(list(results.keys()), false_negatives, color=colors)\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('False Negatives')\n",
        "ax.set_title('False Negative Analysis (Clinical Risk)')\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. AUC Comparison with Error Bars\n",
        "ax = axes[1, 2]\n",
        "models_list = list(results.keys())\n",
        "aucs = [results[m]['auc'] for m in models_list]\n",
        "stds = [cv_results[m]['std_auc'] for m in models_list]\n",
        "ax.bar(models_list, aucs, yerr=stds, capsize=5, color='purple', alpha=0.7)\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('AUC')\n",
        "ax.set_title('AUC Comparison with Standard Deviation')\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.set_ylim([0.9, 1.0])\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{RESULTS_DIR}/comprehensive_analysis.png\", dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(f\"✓ Comprehensive analysis plot saved to {RESULTS_DIR}/comprehensive_analysis.png\")\n",
        "\n",
        "# ==========================================\n",
        "# FINAL SUMMARY REPORT\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL SUMMARY REPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "summary_report = f\"\"\"\n",
        "ECG CLASSIFICATION - COMPREHENSIVE ANALYSIS REPORT\n",
        "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n",
        "DATASET INFORMATION:\n",
        "- Total Samples: {len(y_combined)}\n",
        "- Training Samples: {len(y_train)}\n",
        "- Test Samples: {len(y_test)}\n",
        "- Features Extracted: {X_combined_features.shape[1]}\n",
        "- Class Balance (Train): Normal={((y_train==0).sum())}, Abnormal={((y_train==1).sum())}\n",
        "\n",
        "BEST MODEL: Random Forest\n",
        "- Test Accuracy: {results['Random Forest']['accuracy']:.4f}\n",
        "- Test AUC: {results['Random Forest']['auc']:.4f}\n",
        "- Cross-validation AUC: {cv_results['Random Forest']['mean_auc']:.4f} ± {cv_results['Random Forest']['std_auc']:.4f}\n",
        "- 95% CI: [{cv_results['Random Forest']['95%_ci_lower']:.4f}, {cv_results['Random Forest']['95%_ci_upper']:.4f}]\n",
        "- Sensitivity: {results['Random Forest']['sensitivity']:.4f}\n",
        "- Specificity: {results['Random Forest']['specificity']:.4f}\n",
        "- False Negatives: {results['Random Forest']['false_negatives']}\n",
        "- Training Time: {computational_costs['Random Forest']['Training Time (s)']:.2f} seconds\n",
        "- Memory Usage: {computational_costs['Random Forest']['Memory Usage (MB)']:.2f} MB\n",
        "\n",
        "STATISTICAL SIGNIFICANCE:\n",
        "Random Forest vs other models - see statistical_significance_tests.csv for details\n",
        "\n",
        "INTERPRETABILITY:\n",
        "- SHAP values generated for feature importance\n",
        "- Top features identified and visualized\n",
        "\n",
        "FILES GENERATED:\n",
        "1. comprehensive_model_comparison.csv\n",
        "2. computational_cost_analysis.csv\n",
        "3. statistical_significance_tests.csv\n",
        "4. dataset_characteristics.txt\n",
        "5. shap_summary_plot.png\n",
        "6. shap_feature_importance.png\n",
        "7. comprehensive_analysis.png\n",
        "\n",
        "PROBLEMS ADDRESSED:\n",
        "✓ Q1: Dataset characteristics documented\n",
        "✓ Q2: Note on patient-level splitting added\n",
        "✓ Q3: Class imbalance handled via stratification\n",
        "✓ Q5: Features extracted and analyzed\n",
        "✓ Q6: Cross-validation and hyperparameter tuning performed\n",
        "✓ Q7: Computational cost fully analyzed\n",
        "✓ Q8: Clinical metrics (sensitivity, specificity, FN) reported\n",
        "✓ Q9: Statistical significance tests performed\n",
        "✓ Q11: SHAP interpretability analysis completed\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{RESULTS_DIR}/SUMMARY_REPORT.txt\", 'w') as f:\n",
        "    f.write(summary_report)\n",
        "\n",
        "print(summary_report)\n",
        "print(f\"\\n✓ Full summary report saved to {RESULTS_DIR}/SUMMARY_REPORT.txt\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANALYSIS COMPLETE!\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}